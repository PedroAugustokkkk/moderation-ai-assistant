# üõ°Ô∏è SafeView AI - Assistente de Modera√ß√£o de Risco (v4.2)

> Um prot√≥tipo de Computer Vision (CV) que automatiza a modera√ß√£o de risco, seguran√ßa e receita para qualquer plataforma de conte√∫do gerado pelo usu√°rio (UGC), marketplace ou rede social.

Este projeto demonstra uma solu√ß√£o de engenharia de n√≠vel profissional que vai al√©m da simples modera√ß√£o de "nudez". Ele √© uma ferramenta de **gerenciamento de risco** e **prote√ß√£o de receita**, projetada para resolver os problemas operacionais centrais de qualquer plataforma que dependa de uploads de usu√°rios.
Caso deseje testar a ferramenta agora, basta acessar a URL: https://moderation-ai.streamlit.app

## üéØ O Desafio de Neg√≥cio

Plataformas de conte√∫do UGC vivem um dilema constante:
1.  **Risco Legal (Seguran√ßa):** Conte√∫do ilegal (viol√™ncia, armas, drogas) ou que indique coer√ß√£o (tr√°fico humano) √© um risco jur√≠dico e de marca gigantesco.
2.  **Risco de Receita (Fraude):** Usu√°rios que burlam a plataforma colocando informa√ß√µes de contato (WhatsApp, @) nas imagens para evitar taxas (vazamento de receita).
3.  **Custo Operacional (OPEX):** A necessidade de uma equipe humana cara para filtrar manualmente *milhares* de imagens 24/7, gerando gargalo.
4.  **Calibra√ß√£o:** Como diferenciar conte√∫do `adult` (expl√≠cito e proibido) de `racy` (sensual ou "lim√≠trofe"), que pode ser permitido dependendo das regras da plataforma?

## üí° A Solu√ß√£o: Um "Porteiro" Multi-Modelo e Calibr√°vel

O "SafeView AI" n√£o √© um "censor" r√≠gido; √© um "porteiro" inteligente que usa 4 modelos de IA simultaneamente para tomar uma decis√£o em 1 segundo:

1.  **Prote√ß√£o de Receita (OCR):** L√™ o texto nas imagens para bloquear n√∫meros de telefone e @ de redes sociais.
2.  **Prote√ß√£o de Risco (WAD):** Bloqueia imagens com `armas`, `drogas` ou `√°lcool` expl√≠cito.
3.  **Prote√ß√£o Humana (Face/Emo√ß√£o):** Sinaliza imagens onde o rosto detectado apresenta emo√ß√µes negativas fortes (tristeza, raiva), enviando-as para revis√£o humana priorit√°ria por suspeita de coer√ß√£o ou cyberbullying.
4.  **Prote√ß√£o de Conte√∫do (Nudity 2.0):** Bloqueia nudez expl√≠cita (`sexual_activity`), com um threshold que pode ser ajustado.

## ‚ú® Funcionalidades Profissionais

* **Painel de Calibra√ß√£o (Admin):** Esta √© a "killer feature". A l√≥gica n√£o √© "hardcoded". Um painel na sidebar permite que o time de Produto/Modera√ß√£o ajuste a *sensibilidade* (o "aperto") de cada filtro (Nudez, Armas, Emo√ß√£o) em tempo real, sem precisar de um novo deploy de c√≥digo.
* **Veredito Multi-Viola√ß√£o:** O sistema acumula todas as regras quebradas e apresenta um relat√≥rio completo (ex: `REPROVADA: [Contato Detectado, Arma Detectada]`).
* **API Freemium:** Utiliza a stack da **Sightengine**, que n√£o requer cart√£o de cr√©dito para prototipagem, tornando o projeto 100% acess√≠vel.

## üõ†Ô∏è Stack de Tecnologia

* **Frontend:** Streamlit
* **Computer Vision API:** Sightengine
* **Modelos Utilizados:** `nudity-2.0`, `wad` (Weapons/Alcohol/Drugs), `text` (OCR), `face-attributes` (Emo√ß√£o).

## üöÄ Como Executar Localmente

1.  Clone o reposit√≥rio.
2.  Crie e ative um ambiente virtual (`python -m venv .venv` e `source .venv/bin/activate`).
3.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```

4.  Adquira suas credenciais:
    * Crie uma conta gratuita no [Sightengine.com](https://sightengine.com/).
    * No dashboard, ative os modelos: `nudity-2.0`, `wad`, `text`, `face-attributes`.
    * Pegue seu `API User` e `API Secret`.

5.  Configure suas credenciais (crie este arquivo):

    **Arquivo: `.env`**
    ```plaintext
    SIGHTENGINE_USER="SEU_API_USER_AQUI"
    SIGHTENGINE_SECRET="SEU_API_SECRET_AQUI"
    ```

6.  (Opcional, mas recomendado) Crie um `.gitignore` para proteger seu `.env`.
    ```plaintext
    .venv/
    *.env
    __pycache__/
    ```

7.  Execute a aplica√ß√£o:
    ```bash
    streamlit run app.py
    ```
